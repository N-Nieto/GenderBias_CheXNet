[DEFAULT]
; working directory. It should include all folds (fx_male, fx_female) and model (modelo_x) splits
output_dir=Cross_validation_splits/

; all images should be placed under this dir
image_source_dir=./colab_directory/images/

; base model name
; one of: VGG16, VGG19, DenseNet121, ResNet50, InceptionV3, InceptionResNetV2,
; NASNetMobile, NASNetLarge
base_model_name=DenseNet121

; class names, you should not modify this
class_names=Atelectasis,Cardiomegaly,Effusion,Infiltration,Mass,Nodule,Pneumonia,Pneumothorax,Consolidation,Edema,Emphysema,Fibrosis,Pleural_Thickening,Hernia

[TRAIN]
; use base model weights or not. If true, imagenet pretrained weights will be used.
use_base_model_weights=true

; if true, load trained model weights saved in output_dir
; this is typically used for resuming your previous training tasks
; so the use_split_dataset will be automatically set to false
; also, make sure you use the reasonable initial_learning_rate
use_trained_model_weights=false

; if true, use best weights, else use last weights
use_best_weights=true

; if true, save best weights only (the weights are not overwritten if val is not improved). Otherwise save the last weights always.
save_best_only=true

; note that the best weighting will be saved as best_weights.h5
output_weights_name=weights.h5

; basic training parameters
epochs=15
batch_size=32

; learning rate options
initial_learning_rate=0.01

; worker number of the image generators
generator_workers=8

; target width/height of the input image (resized)
image_dimension=224

; steps per epoch for training
; auto or int
; if auto is set, (total samples / batch_size / 10) is used by default.
train_steps=auto

; steps per epoch for validation
; auto or int
; if auto is set, (total samples / batch_size / 5) is used by default.
validation_steps=auto

; patience parameter used for ReduceLROnPlateau callback
; If val_loss doesn't decrease for x epochs, learning rate will be reduced by factor of 10.
patience_reduce_lr=1

; minimun learning rate
min_lr=1e-8

; this variable controlls the class_weight ratio between 0 and 1
; higher value means higher weighting of positive samples
positive_weights_multiply=1

; path of the folder that contains train.csv|dev.csv|test.csv
#dataset_csv_dir=./experiments/NoFilter

; print model summary
show_model_summary=true

[FINETUNE]
; use base model weights or not. If true, imagenet pretrained weights will be used.
use_base_model_weights=true

; if true, load trained model weights saved in output_dir
; this is typically used for resuming your previous training tasks
; so the use_split_dataset will be automatically set to false
; also, make sure you use the reasonable initial_learning_rate
use_trained_model_weights=true

; if true, use best weights, else use last weights
use_best_weights=true

; if true, save best weights only (the weights are not overwritten if val is not improved). Otherwise save the last weights always.
save_best_only=true

; note that the best weighting will be saved as best_weights.h5
output_weights_name=weights.h5

; basic training parameters
epochs=10
batch_size=32

; learning rate options
initial_learning_rate=0.01

; worker number of the image generators
generator_workers=1

; target width/height of the input image (resized)
image_dimension=224

; steps per epoch for training
; auto or int
; if auto is set, (total samples / batch_size / 10) is used by default.
train_steps=auto

; steps per epoch for validation
; auto or int
; if auto is set, (total samples / batch_size / 5) is used by default.
validation_steps=auto

; patience parameter used for ReduceLROnPlateau callback
; If val_loss doesn't decrease for x epochs, learning rate will be reduced by factor of 10.
patience_reduce_lr=1

; minimun learning rate
min_lr=1e-8

; this variable controlls the class_weight ratio between 0 and 1
; higher value means higher weighting of positive samples
positive_weights_multiply=1

; path of the folder that contains train.csv|dev.csv|test.csv
#dataset_csv_dir=./experiments/NoFilter

; print model summary
show_model_summary=true

[TEST]
batch_size=1
test_steps=auto
test_generator_random_state=1
; if true, use best_weights.h5, else use weights.h5
use_best_weights=true

[FINETUNE_TEST]
batch_size=32
test_steps=auto
test_generator_random_state=1
; if true, use best_weights.h5, else use weights.h5
use_best_weights=true

[CAM]
bbox_list_file=./data/BBox_List_2017.csv
use_best_weights=true
